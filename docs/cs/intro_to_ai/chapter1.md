# 知识表达和推理

<!-- 一、命题逻辑
二、谓词逻辑
三、知识图谱推理
四、概率图推理
五、因果推理 -->

目前代表性知识表达方法有命题逻辑、谓词逻辑、产生式规则（production rule）、框架（frame）表示法以及知识图谱等。

## 命题逻辑

- 原子命题：不包含其他命题作为其组成部分的命题，又称简单命题。
- 复合命题：包含其他命题作为其组成部分的命题
- 命题连接词：
    - 与(and)：$p \land q$ 命题合取(conjunction)
    - 或(or)：$p \lor q$ 命题析取(disjunction)
    - 非(not)：$\lnot p$ 命题否定(negation)
    - 条件(conditional)：$p \to q$ 命题蕴含(implication)
    - 双向条件(bi-conditional)：$p \leftrightarrow q$ 命题双向蕴含(bi-implication)

## 谓词逻辑

- 谓词逻辑：刻画主体（个体和群体）之间逻辑关系的方法
- 分解出个题、谓词和量词

    - 个体：个体是指所研究领域中可以独立存在的具体或抽象的概念。
    - 谓词：谓词是用来刻画个体属性或者描述个体之间关系存在性的元素，其值为真或为假
        - 包含一个参数的谓词称为一元谓词，表示一元关系，通常用于刻画个体是否包含特定的属性，如 $P(x):x$ 是质数，表示某个数是否是质数
        - 包含多个参数的谓词称为多元谓词，用于表示个体之间的多元关系，通常用于描述个体之间是否存在特定的关联。

- 全称量词和存在量词

    - 全称量词：$\forall x$，表示对于所有的个体 $x$。
    - 存在量词：$\exists x$，表示存在一个个体 $x$。

- 谓词逻辑推理的手段

    - 全称量词消去(universal instantiation, UI)：$(\forall x)A(x) \Rightarrow A(y)$
    - 全称量词引入(universal generalization, UG)：$A(y) \Rightarrow (\forall x)A(x)$
    - 存在量词消去(existential instantiation, EI): $(\exists x)A(x) \Rightarrow A(c)$
    - 存在量词引入(existential generalization, EG): $A(c) \Rightarrow (\exists x)A(x)$

## 知识图谱推理

知识图谱(knowledge graph)由有向图(directed graph)构成，被用来描述现实世界中实体及实体之间的关系。

每个节点表示客观世界中的一个实体，两个节点之间的连线表示节点具有某一关系。

知识图谱中存在连线的两个实体可表达为形如 `<left_node，relation，right_node>` 的三元组形式，这种三元组也可以表示为一阶逻辑(first order logic, FOL)的形式，从而为基于知识图谱的推理创造了条件。

!!! note "归纳学习"

    如果定义如下推理规则：

    \[
    (\forall x)(\forall y)(\forall z)(Mother(z, y) \land Couple(x, z) \to Father(x, y))
    \]

    就可在现有知识 $Mother(James, Ann)$ 和 $Couple(James, David)$ 基础上进行推理，得到新的知识 $Father(David, Ann)$，即补充了 David 和 Ann 的关系，从而对原来的知识图谱进行了完善，扩展了实体之间的关系。

- FOIL（First Order Inductive Learner）算法

    <div align=center><img src="/assert/img/CS/ai/chapter1/foil.png" width = 90%/></div>

    在 FOIL 中，目标谓词是需要推断规则的结论，也称为规则头。在给定推理结论后，FOIL 算法学习得到使得结论满足的前提条件，即目标谓词作为结论的推理规则。

    即由结论学习得到前提条件。

    - 正例、反例和背景样例

        为了学习推理规则，需要构造目标谓词 $P$ 的训练样例，训练样例包含正例集合 $E^+$ 和反例集合 $E^-$。

        此外在推理中还需要其他背景知识，这些背景知识来自知识图谱中目标谓词以外的其他谓词实例化结果。

    - 算法思路

        从一般到特殊，逐步添加目标谓词的前提约束谓词，直到所构成的推理规则不覆盖任何反例。从一般到特殊指的是对目标谓词或前提约束谓词中的变量赋予具体值。

        添加前提约束谓词后所得推理规则的质量好坏由信息增益值 (information gain) 这一评估准则来判断。

- 路径排序推理算法

    路径排序推理算法（PRA）的基本思想是将实体之间的关联路径作为特征，来学习目标关系的分类器。

    工作流程：

    - 特征抽取：生成并选择路径特征集合。生成路径的方式有随机游走（random walk）、广度优先搜索、深度优先搜索等。
    - 特征计算：计算每个训练样例的特征值 $P(s \to t;\pi_j)$。该特征值可以表示从实体节点 $s$ 出发，通过关系路径 $\pi_j$ 到达实体节点 $t$ 的概率；也可以表示为布尔值，表示实体 $s$ 到实体 $t$ 之间是否存在路径 $\pi_j$；还可以是实体 $s$ 和实体 $t$ 之间路径出现频次、频率等。
    - 分类器训练：根据训练样例的特征值，为目标关系训练分类器。当训练好分类器后，即可将该分类器用于推理两个实体之间是否存在目标关系。

## 概率图推理

用概率描述两个相连节点之间的关联，称为概率图（probabilistic graph），而基于概率图进行的推理被称为概率推理。

概率图模型一般分为贝叶斯网络（Bayesian Network）和马尔可夫网络（Markov Network）两大类。

- 贝叶斯网络：用一个有向无环图（directed acyclic graph）来表示，其用有向边来表示节点和节点之间的单向概率依赖。
- 马尔可夫网络：表示成一个无向图的网络结构，其用无向边来表示节点和节点之间的相互概率依赖。

### 贝叶斯网络

贝叶斯网络满足局部马尔可夫性（local Markov property），即在给定一个节点的父节点的情况下，该父亲节点有条件地独立于它的非后代节点（non-descendant）。

贝叶斯网络中所有因素的联合分布等于所有节点的 $P(\text{节点}|\text{父节点})$ 的乘积。

### 马尔可夫网络

从概率统计角度来看，马尔可夫逻辑网络不仅简洁明了描述了马尔可夫网（Markov networks，简称 MNs）中所存在信息之间关联，还因在马尔可夫网络中引入谓词逻辑融入了结构化知识。

从一阶谓词逻辑角度来看，马尔可夫逻辑网在一阶谓词逻辑中添加了不确定性而对严格推理进行了松绑，更好反映了客观世界的复杂性。

## 因果推理

!!! info "辛普森悖论（Simpson's Paradox）"

    辛普森悖论表明，在某些情况下，忽略潜在的“第三个变量”，可能会改变已有的结论，而我们常常会忽略这一因素。

- 因果关联：数据中两个变量，如一个变量是另一个变量的原因，则该两变量之间存在因果关联。
- 混淆关联：数据中待研究的两个变量之间存在共同的原因变量。
- 选择关联：数据中待研究的两个变量之间存在共同的结果变量。

### 因果分析的两种理论框架

- 潜在结果框架（Potential Outcome Framework）：也被称为 Neyman–Rubin 因果模型。
- 结构因果模型（Structure Causal Model, SCM）

    结构因果图是一种有向无环图。有向无环图刻画了图中所有节点之间的依赖关系。DAG 可用于描述数据的生成机制。这样描述变量联合分布或者数据生成机制的模型，被称为 “贝叶斯网络”（Bayesian network）。

    !!! note "因果图的优势"

        对于任意的有向无环图模型，模型中 $d$ 个变量的联合概率分布由每个节点与其父节点之间条件概率 $P(child|parents)$ 的乘积给出：

        \[
        P(x_1, x_2, \cdots, x_d) = \prod_{i=1}^d P(x_i|parents(x_i))
        \]